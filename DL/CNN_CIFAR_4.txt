from keras.datasets import cifar10
import tensorflow as tf
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt

# a. Loading and preprocessing the data.
((train_images, train_labels),(test_images, test_labels))=cifar10.load_data()
train_images=train_images/255.0
test_images=test_images/255.0
class_names = ['airplpane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']

plt.figure(figsize=(10,10))
for i in range(10):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i])
    plt.xlabel(class_names[train_labels[i][0]])
plt.show()

# b. Defining the model's architecture 
model = models.Sequential()
model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Conv2D(64, (3,3), activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Conv2D(64, (3,3), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10, activation='softmax'))
model.summary()

# Training the model
from keras.losses import SparseCategoricalCrossentropy
from keras.optimizers import SGD
sgd=SGD(0.01)
model.compile(loss='sparse_categorical_crossentropy',optimizer='sgd', metrics=['accuracy'])
epoch=10
h=model.fit(train_images,train_labels, validation_data=(test_images,test_labels), epochs=epoch)

# Model performance
test_loss, test_acc = model.evaluate(test_images, test_labels)
print("Test Loss: {}, Test Accuracy: {}".format(test_loss, test_acc))

plt.plot(h.history['accuracy'], label='acc', color='red')
plt.plot(h.history['val_accuracy'], label='val_acc', color='green')
plt.legend()

print(h.history.keys())

plt.plot(h.history['accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(h.history['loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

image_index = 3333
plt.imshow(test_images[image_index].reshape(32, 32, 3),cmap='Greys')
pred = model.predict(test_images[image_index].reshape(1, 32, 32, 3))
print(pred.argmax())  


"""  This practical demonstrates how to implement a Convolutional Neural Network (CNN) to classify images in the CIFAR-10 dataset using TensorFlow and Keras. Here’s a detailed overview of each stage, along with potential viva questions and answers.

Practical Overview
Stage A: Loading and Preprocessing the Image Data
Dataset Loading: The CIFAR-10 dataset is loaded using cifar10.load_data(). CIFAR-10 consists of 60,000 32x32 color images across 10 classes, including airplanes, automobiles, birds, cats, etc.
Normalization: Images are normalized by dividing the pixel values by 255.0. This scales the pixel values to a range of 0-1, which speeds up training and helps the model converge by standardizing the input data.
Class Names: Each label in CIFAR-10 corresponds to one of ten classes, such as airplane, automobile, bird, etc., which are stored in class_names.
Visualizing Sample Images: A 5x5 grid of sample images is displayed with labels, helping you understand what each class looks like and confirming that the dataset loaded correctly.
Stage B: Defining the Model’s Architecture
The model uses a sequential structure with multiple layers:

Convolutional Layers: The first three layers are convolutional (Conv2D) layers with 32 and 64 filters, each using a 3x3 kernel. These layers extract spatial features from images, like edges, textures, and shapes.
Pooling Layers: After each Conv2D layer, a MaxPooling2D layer with a 2x2 window reduces the spatial dimensions by downsampling, which reduces computational load and captures dominant features.
Flatten Layer: The output from the final Conv2D layer is flattened into a 1D array, preparing it for the dense (fully connected) layers.
Dense Layers: A fully connected layer with 64 neurons and ReLU activation is added to learn higher-level features. The final layer uses 10 neurons with softmax activation, representing the probability distribution across the 10 classes.
Stage C: Training the Model
Compilation: The model is compiled using the SGD optimizer with a learning rate of 0.01. SparseCategoricalCrossentropy is used as the loss function, suitable for multi-class classification when the labels are in integer form.
Training: The model is trained for 10 epochs, and validation data (test set) is provided to monitor how well the model generalizes to unseen data.
Stage D: Estimating the Model’s Performance
Evaluation: The trained model is evaluated on the test set, yielding the test loss and accuracy. This provides a final metric to assess the model's performance.
Plotting Training Progress: Training and validation accuracy and loss over epochs are plotted, showing whether the model is overfitting (training accuracy high but validation accuracy low) or underfitting (both accuracies low).
Prediction on a Sample Image: Finally, a sample test image is displayed, and the model’s prediction for that image is printed. This tests the model’s classification ability on an individual case.
Summary of the Practical
This practical demonstrates how to implement a CNN for classifying CIFAR-10 images, including image preprocessing, model architecture, training, evaluation, and visualization. CNNs are ideal for image classification tasks as they capture spatial patterns and hierarchies in images through convolutional layers, resulting in better performance than feedforward networks.

Viva Questions and Suggested Answers
Why is normalization important for the images?

Answer: Normalization scales the pixel values between 0 and 1, making training more efficient and stabilizing the learning process, as the network does not have to adjust for large differences in input values.
What is the purpose of a convolutional layer?

Answer: A convolutional layer applies filters to input images to detect various spatial features, such as edges, textures, and shapes. This helps the model learn image patterns and improve its classification ability.
Why do we use max pooling after convolutional layers?

Answer: Max pooling reduces the spatial dimensions, thereby reducing computation, preventing overfitting, and retaining dominant features in the feature maps. This helps the model generalize better to new data.
Explain the role of the softmax activation function in the output layer.

Answer: Softmax converts the output into a probability distribution, where each neuron’s value represents the probability of the image belonging to a specific class. It helps in multi-class classification by selecting the class with the highest probability.
What is the purpose of the Flatten layer?

Answer: The Flatten layer reshapes the 2D matrix output from the convolutional layers into a 1D vector, making it compatible with the fully connected layers. This step is essential for transitioning from spatial features to classification.
Why do we use SparseCategoricalCrossentropy as the loss function?

Answer: SparseCategoricalCrossentropy is used for multi-class classification when labels are provided as integers (e.g., 0 to 9 for CIFAR-10). It calculates the cross-entropy loss between true and predicted labels, which helps in optimizing the model for accurate classification.
What is the purpose of using a validation set during training?

Answer: The validation set allows us to evaluate the model on unseen data during training, helping us monitor how well the model generalizes. This helps identify overfitting, where the model performs well on training data but poorly on validation data.
Why might CNNs perform better on image data compared to feedforward neural networks?

Answer: CNNs capture spatial hierarchies and patterns in images through convolution and pooling operations, which feedforward networks do not. CNNs learn local features and structures, making them more effective for image data.
Why do we use the SGD optimizer in this practical?

Answer: The SGD (Stochastic Gradient Descent) optimizer helps minimize the loss by updating the model weights. It’s simple and effective for relatively shallow architectures. Its learning rate of 0.01 is moderate and provides stable convergence.
What could it indicate if the training accuracy is high but the validation accuracy is low?

Answer: This usually indicates overfitting, meaning the model has learned the training data very well but is unable to generalize to unseen data. The model may need regularization or more data to improve its generalization.
What does the plot of training and validation loss over epochs tell us?

Answer: The plot helps us understand the model’s learning process. If the training and validation loss decrease and converge, the model is learning well. If they diverge, it could indicate overfitting or underfitting.
How could the performance of this CNN model be further improved?

Answer: Performance could be improved by adding more layers, increasing the number of filters, using data augmentation, or applying regularization techniques like dropout to prevent overfitting.
Summary Explanation
This practical covers implementing a CNN for image classification on CIFAR-10. It includes data preprocessing, defining the CNN model architecture, training with SGD, evaluating, and visualizing model performance. CNNs excel at image classification due to their ability to capture spatial features, and the CIFAR-10 dataset offers a challenging but achievable benchmark for evaluating CNN architectures.""" 