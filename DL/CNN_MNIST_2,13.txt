import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.utils import to_categorical
import numpy as np
import matplotlib.pyplot as plt

# Stage A: Loading and Preprocessing the Image Data
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train = x_train.reshape(-1, 28, 28, 1).astype("float32") / 255.0
x_test = x_test.reshape(-1, 28, 28, 1).astype("float32") / 255.0
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

# Stage B: Defining the Model's Architecture
model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3), activation="relu", input_shape=(28, 28, 1)))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(64, kernel_size=(3, 3), activation="relu"))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())
model.add(Dense(128, activation="relu"))
model.add(Dense(10, activation="softmax"))

# Stage C: Training the Model
model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])
model.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_test, y_test))

# Stage D: Estimating the Model's Performance
test_loss, test_accuracy = model.evaluate(x_test, y_test)
print(f"Test accuracy: {test_accuracy * 100:.2f}%")

# Visualizing and Verifying Predictions
index = np.random.randint(0, len(x_test))
test_image = x_test[index]
actual_label = np.argmax(y_test[index])
test_image_batch = np.expand_dims(test_image, axis=0)
predicted_probs = model.predict(test_image_batch)
predicted_label = np.argmax(predicted_probs)

plt.imshow(test_image.squeeze(), cmap='gray')
plt.title(f"Predicted: {predicted_label}, Actual: {actual_label}")
plt.axis('off')
plt.show()

if predicted_label == actual_label:
    print("Correct classification!")
else:
    print("Incorrect classification.")


""" Here’s a detailed breakdown of this practical implementation, including the purpose of each stage and potential viva questions.

Practical Overview
Stage A: Loading and Preprocessing the Image Data
Loading Data: The MNIST dataset is loaded using mnist.load_data(). This dataset consists of grayscale images of handwritten digits (28x28 pixels), split into training and testing sets.
Reshaping Data: The images are reshaped to (28, 28, 1) to add a channel dimension, required for convolutional layers.
Normalizing Pixel Values: Pixel values are scaled between 0 and 1 by dividing by 255.0, which improves convergence during training by reducing the scale of input values.
One-Hot Encoding Labels: The labels are converted to one-hot encoded vectors using to_categorical, which allows the model to treat each output class separately during classification.
Stage B: Defining the Model's Architecture
Convolutional Layers (Conv2D): The model uses two convolutional layers:
First Conv2D Layer: 32 filters with a kernel size of (3,3) and ReLU activation, which helps extract features from the images.
MaxPooling2D: A pooling layer that reduces the spatial size of the feature maps, helping reduce computation and control overfitting.
Second Conv2D Layer: 64 filters with a kernel size of (3,3) and ReLU activation, extracting more complex features from the pooled feature maps.
MaxPooling2D: Another pooling layer to further down-sample the feature maps.
Flatten Layer: Converts the 2D feature maps into a 1D vector, allowing them to connect with the dense layers.
Dense Layers:
Hidden Dense Layer: 128 neurons with ReLU activation for non-linear mapping and further feature extraction.
Output Dense Layer: 10 neurons with softmax activation, which outputs class probabilities for each of the 10 digits.
Stage C: Training the Model
Compiling the Model: The model uses the Adam optimizer, which adapts the learning rate and generally performs well for image data. categorical_crossentropy is used as the loss function since this is a multi-class classification problem.
Model Fitting: The model is trained for 10 epochs with a batch size of 128. Validation is performed on the test data during training to monitor performance on unseen data.
Stage D: Estimating the Model's Performance
Evaluating Test Performance: The evaluate method provides the final accuracy and loss on the test set.
Displaying a Sample Prediction:
A random test image is selected, and the model predicts its label.
The predicted label is compared with the actual label, and both are displayed along with the image for visual verification.
Summary of the Practical
This practical involves building a CNN to classify images from the MNIST dataset, leveraging the network’s ability to learn spatial hierarchies of features. The CNN architecture, composed of convolutional and dense layers, is trained using labeled MNIST images, with accuracy improvements through techniques like normalization and pooling. Finally, the model’s performance is evaluated, and individual predictions are checked visually to ensure correct classification.

Viva Questions and Suggested Answers
Why do we reshape the images to (28, 28, 1)?

Answer: The additional dimension (1) represents the channel for grayscale images, which is necessary for CNNs. Without this channel dimension, convolutional layers would not process the images correctly.
Why is normalization important in this model?

Answer: Normalization (scaling pixel values to 0–1) helps stabilize and speed up training by ensuring that input values are within a consistent range.
Explain the purpose of convolutional layers in CNNs.

Answer: Convolutional layers apply filters to input images to extract important features, like edges, textures, and shapes, allowing the network to learn spatial hierarchies of features.
What is MaxPooling, and why is it used here?

Answer: MaxPooling downsamples the feature maps by selecting the maximum value in each region, reducing spatial size and computational load while retaining important features.
What is the role of the Flatten layer in CNNs?

Answer: Flatten converts the 2D feature maps into a 1D vector, allowing the data to be fed into the fully connected (dense) layers for final classification.
Why is ReLU used as the activation function in convolutional and dense layers?

Answer: ReLU (Rectified Linear Unit) introduces non-linearity by setting negative values to zero, helping the model learn complex patterns while avoiding issues like the vanishing gradient problem.
Why do we use softmax activation in the output layer?

Answer: Softmax converts the output values to probabilities that sum to 1, which is essential for multi-class classification to predict the likelihood of each class.
What is categorical cross-entropy, and why is it suitable here?

Answer: Categorical cross-entropy measures the difference between the predicted probability distribution and the true distribution, making it suitable for multi-class classification tasks.
What is the purpose of the Adam optimizer, and why is it chosen?

Answer: Adam is an adaptive learning rate optimizer that combines the benefits of momentum and RMSProp, making it effective for a wide range of deep learning tasks.
How does the model estimate its performance on the test set?

Answer: The model uses the evaluate function to calculate loss and accuracy on the test set, indicating its generalization performance.
Why do we plot a random prediction, and how is it useful?

Answer: Plotting a random prediction allows us to visually verify the model’s accuracy on specific cases, helping to check if the model correctly identifies the digit.
Summary Explanation
This implementation showcases the full process of using a CNN for image classification on the MNIST dataset. The model includes several stages, from data preprocessing and model architecture to training and performance evaluation. By understanding key concepts like convolution, pooling, activation functions, and evaluation metrics, this practical exercise illustrates the fundamental building blocks of CNNs for image recognition tasks."""